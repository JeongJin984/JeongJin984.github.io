I"L<h1 id="cpu--gpu"><strong>CPU &amp; GPU</strong></h1>
<hr />

<h2 id="cpu">CPU</h2>
<blockquote>
  <p>컴퓨터 시스템을 통제하고 프로그램의 연산을 실행하고 처리하는 가장 핵심적인 컴퓨터의 제어 장치</p>
</blockquote>

<ul>
  <li>수많은 작업을 수행할 수 있는 범용 처리 장치</li>
</ul>

<h2 id="gpu">GPU</h2>
<blockquote>
  <p>고해상도의 이미지와 비디오를 고속으로 처리할 수 있도록 설계된 프로그래밍 가능한 프로세서</p>
</blockquote>

<ul>
  <li>수천개의 프로세싱 코어가 동시에 다수의 데이터에 병렬 동작을 수행</li>
  <li>GPGPU(General-Purpose computing on GPU)
    <ul>
      <li>GPU의 실시간 대량 연산 특성을 활용해 특정 영역에서  CPU보다 좋은 계산 능력을 보여줄 수 있음</li>
    </ul>
  </li>
  <li>딥러닝에서 GPGPU 사용의 장점
    <ul>
      <li>다수의 연산을 동시에 실행 -&gt; 대규모 행렬연산에 적합</li>
      <li>다수의 GPU 동시 사용으로 병렬로 알고리즘 수행</li>
      <li>CPU보다 저렴한 cost
-CPU 와 GPU의 동시 수행</li>
      <li>GPU는 스트리밍 방식의 순차 접근 패턴에 최적화</li>
      <li>CPU는 일반 접근 패턴과 쓰레드의 동시 처리를 위해 설계됨</li>
      <li>CPU 와 GPU가 결합되어 GPGPU 파이프라인을 형성 -&gt; 데이터 분석에 최적</li>
    </ul>
  </li>
</ul>

<h2 id="cudacompute-unified-device-architecture">CUDA(Compute Unified Device Architecture)</h2>

<blockquote>
  <p>Nvidia 에서 개발한 병렬 컴퓨팅 플랫폼 및 프로그래밍 API</p>
</blockquote>

<ul>
  <li>GPU 가상 명령셋과 병렬 계산 요소에 대한 직접적인 접근을 제공하는 소프트웨어 계층</li>
  <li>CUDA Compute Capability(CC)
    <blockquote>
      <p>Cuda의 일반 명세와 가능한 기능을 수치화 한 것</p>
    </blockquote>
    <ul>
      <li>제품화된 GPU는 1.0~1.5의 값을 가징</li>
    </ul>
  </li>
  <li>GPU의 성능 확인
    <ul>
      <li>Cuda Core 갯수: 병렬 연산 속도 결정</li>
      <li>GPU 메모리: 한번에 읽어 들일 수 있는 모델의 크기(6GB~권장)</li>
    </ul>
  </li>
</ul>

<h2 id="cuda-python-api">CUDA Python API</h2>
<ul>
  <li>PyCUDA
    <ul>
      <li>Nvidia CUDA 병렬 계산 API의 Python Wrapper</li>
    </ul>
  </li>
  <li>Cupy
    <ul>
      <li>Nvidia VUDA의 가속을 지원하는 Numpy 와 유사한 행렬 연산 라이브러리</li>
    </ul>
  </li>
  <li>Scikit-CUDA
    <ul>
      <li>CUDA 런타임, CUDA 라이브러리의 함수를 실행해주는 Python 인터페이스</li>
    </ul>
  </li>
  <li>딥러닝 플랫폼
    <ul>
      <li>Tensorflow, Pytorch, Chainer. MxNet</li>
    </ul>
  </li>
</ul>

<h2 id="다운로드">다운로드</h2>
<ul>
  <li>GPU가 없어서 CUDA 사용 불가.</li>
</ul>
:ET