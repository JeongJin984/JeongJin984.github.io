---
title: Apache Kafka 2
author: Jiny
date: 2021-06-08 14:30:00 +0800
categories: [DataEngineering, Kafka]
tags: [kafka, data]
toc: false
---
 
# Apache Kafka 2

___

## 💿 **브로커, 클러스터, 주키퍼**

### **브로커**

> 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 App

- **데이터 저장, 전송:** 프로듀서로 부터 전달된 데이터는 파일 시스템에 저장 되며 컨슈머가 데이터를 요청하면 파티션에 저장된 저장된 데이터를 전달한다.
  - 페이지 캐시 영역에 저장하기 때문에 파일 입출력의 속도 문제를 최소화
- **데이터 복제, 싱크:** 복제는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력
  - 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용
  - 데이터 복제는 파티션 단위로 이루어 짐
    - 팔로워들은 리더의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 날 경우 리더로 부터 데이터를 복제해 온다.
    - 리더 파티션이 장애가 발생하면 팔로워 중 하나가 리더 파티션 지위를 넘겨받음
- **컨트롤러(Controller):** 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 분배함
  - 브로커 중 한대가 이 역할을 함
  - 컨트롤러 브로커에 장애가 생기면 다른 브로커가 그 역할을 함
- **데이터 삭제**
  - 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않음
  - 컨슈머나 프로듀서가 데이터를 삭제를 요청할 수 없다.
    - 오직 브로커만이 데이터를 삭제할 수 있음
  - 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 로그 세그먼트라고 함
    - 즉 특정 데이터를 선별해서 삭제 불가
    - 세그먼트 파일은 기본적으로 기본 용량 1GB 도달했을 때 닫힘
    - log.retention.bytes or log.retention.ms를 넘으면 삭제됨
- **컨슈머 오프셋 저장:** 컨슈머 그룹은 토픽이 특정 파티션으로 부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋
  - 커밋된 오프셋은 __CONSUMER_offset 토픽에 저장
    - 여기에 저장된 오프셋을 토대로 컨슈머 그룹은은  다음 레코드를 가져가서 처리함
- **코디네이터:** 컨슈머 그룹ㅇ의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배
  - 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 작동하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 함
    - 이러한 재할당 과정을 리벨런스(rebalance)라고 함

### **주키퍼**

> 카프카의 메타데이터를 관리

- 카프카 브로커에 대한 정보: 보안 규칙, jmx port 상태 정보, host 정보 등
- 컨트롤러 브로커에 대한 정보
- 카프카에 저장된 토픽 확인

### **토픽과 파티션**

> 토픽: 카프카에서 데이터를 구분하기 위해 사용하는 단위

- 토픽은 1개 이상의 파티션을 보유
  - 프로듀서가 보내고 파티션에 저장되는 데이터를 '레코드'라고 함
- 파티션은 카프카의 병렬처리의 핵심으로서 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭 됨
  - 컨슈머 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것
  - 컨슈머의 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량 증가

### **레코드**

> 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성

- 브로커로 전송되면 오프셋과 타입스탬프가 지정되어 저장됨
- 한 번 적재되면 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제 됨
- 타임스탬프: 이를 토대로 레코드가 언제 브로커에 적재되었는지 알 수 있음
- 메시지 키: 메시지를 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용
  - 메시지 키의 해시 값을 토대로 파티션을 지정(즉 동일한 메시지 키라면 동일 파티션에 들어가는 것, 어느 파티션인지는 모름, 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 달라진다.)
  - null이면 기본 설정 파티셔너에 따라서 파티션에 분배
- 메시지 값: 실질적으로 처리할 데이터
  - 메시지 키와 값은 직렬화 되어 브로커에 전송(컨슈머도 동일하게 역직렬화 해야함)
- 레코드 오프셋: 0 이상의 숫자로 이루어져 있음
  - 카프카 컨슈머가 데이터를 가져갈 때 사용
  - 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확히 지정할 수 있음

___

## 💿 **프로듀서**

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcOIEi4%2FbtqCLeNABrw%2FPk6ObbcpmDC508RFExh0vk%2Fimg.png)
_데이터의 전달과정_

1. 프로듀서는 먼저 전달 요청 받은 메시지를 직렬화
   - 메시지의 키와 같은 바이트 뭉치 형태로 변화
2. Partitioner를 통해 토픽의 어떤 파티션에 저장될지 결정합니다.
   - 이러한 과정을 **파티셔닝**이라 함(별도 설정이 없으면 UniformSticky 방식)
   - 다만 이 과정은 메시지 전달 요청에 파티션이 지정되지 않았을 경우에만
3. 만약 메시지 압축이 설정되었다면 설정된 포맷에 맞춰 메시지를 압축
   - 브로커로 빠르게 전달 가능
   - 빠른 복제

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzYz2T%2FbtqCKzqUrYp%2FBqEcMWdf0HS1IUX5yM1vk0%2Fimg.png)
_카프카에서 지원하는 주요 압축 포맷과 효율_

4. 파티셔닝 압축을 마치면 프로듀서는 메시지를 TCP 프로토콜을 통해 브로커의 리더 파티션으로 전송
   - 지정된 만큼 메시지를 모았다가 한번에 브로커로 전달(프로듀서 내부의 Record Accumulator가 담당)
5. Sender가 레코드 배치들을 브로커에 전달
   - Sender는 스레드 형태로 구성되며 관리자가 설정한 특정 조건에 만족한 레코드 배치를 브로커로 전송
6. sender는 설정 값에 따라 브로커의 응답을 기다릴 수 있음
   - 안기다리면 메시지 전송에 대한 과정이 마무리
   - 기다리면 전송 성공 여부를 응답으로 받음 이때 브로커에서 메시지 전송이 실패한 경우에는 설정 값에 따라 재시도를 시도, 성공하면 메타데이터를 반환

___

## 💿 **컨슈머**

